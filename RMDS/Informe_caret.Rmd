---
title: "Predictive model using caret"
author: "Eduardo Roman y Óscar García"
date: "17/4/2019"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections:  true
    df_print: paged
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      cache = TRUE,
                      warning = FALSE, 
                      fig.align = "center")
library(ggplot2)
library(RNetCDF)
library(stringr)
library(lubridate)
library(request)
library(XML)
library(dplyr)
library(TTR)
library(data.table)
library(GGally)
library(e1071)
library(geosphere)
library(imputeTS)
```


# Indroduction


Documento final del predictive moodel de Belesar. Hago esto porque el otro está muy denso y ya cumplio su función esto pretende ser un informe corto y resolutivo sobre el modelo predictivo del caudal que llega a la presa de belesar. Las conclusiones que hemos sacado son las siguientes: 

+ Habrá que predecir aportacion(completa desconocida)  a través de la variación de nivel (WEB SAIH). 

+ La variación de nivel y la aportación están altamenta correlacionadas

+ El modelo consigue buenas predicciones la lluvia observada

```{r include=FALSE}
library(caret)
library(doMC)
library(here)
source(here::here('libraries.R'))

#Cargamos los ultimos datos proporcionados por Actualizar_info_Belesar.R

Obs_Data<- list.files(here::here('Data/Parques/Belesar/Historico/WEB/PM/'), full.names = T) %>% 
  .[str_detect(.,"Obs_")] %>% .[which.max( str_split(., "/") %>% lapply(., function(x) x[length(x)])%>%  str_remove("Obs_|.RDS") %>% 
                                             str_replace("--"," ") %>% ymd_hms())] %>% readRDS()

WRF_data<- list.files(here::here('Data/Parques/Belesar/Historico/WEB/PM/'), full.names = T) %>% 
    .[str_detect(.,"WRF_")] %>% .[which.max( str_split(., "/") %>% lapply(., function(x) x[length(x)])%>%  str_remove("WRF_|.RDS") %>% 
                                               str_replace("--"," ") %>% ymd_hms())] %>% readRDS()

# Tratamos Datos ----------------------------------------------------------
###SOlamente emplearemos los datos de diferencia de nivel ofrecidos por la página web...
### Es decir, a partir de febrero

Tabla_1<- Obs_Data %>% mutate(diff_nivel=c(NA,diff(nivel))) 
Tabla_1<- left_join(Tabla_1, WRF_data[[23]]$D1[,c("Date", "prep_hourly")], by="Date")


# Parte1: Predecir aportacion a partir de diferencia de nivel... 
Tabla_1[,c("Vol","Temp", "porcentaje","prep_hourly")]<- NULL
Tabla_2<- Tabla_1[complete.cases(Tabla_1),]
Tabla_2$aport_SMA<- SMA(Tabla_2$aport, 12)
Tabla_2$difnivel_SMA<- SMA(Tabla_2$diff_nivel, 12)
Tabla_2<- Tabla_2[complete.cases(Tabla_2),]


train_data<- Tabla_2[Tabla_2$Date< ymd("2019/01/25"), ]
prediccion_data<- Tabla_2[Tabla_2$Date> ymd("2019/01/25"), ]



modelo<- train(aport_SMA ~ difnivel_SMA,
               data=train_data,
               method="svmLinear",
               tuneLength=50)


ggplot(data = prediccion_data)+
  geom_line(aes(y=prediccion_data$aport, 
                x=prediccion_data$Date), 
            alpha=0.5)+
  geom_line(aes(y=prediccion_data$aport_SMA, 
                x=prediccion_data$Date), 
            alpha=0.8)+
  ylab("Aportacion [m³/s]")+
  xlab(paste(range(prediccion_data$Date), collapse = "\n"))+
  geom_line(aes(y=predict(modelo, newdata= prediccion_data),
                x=Date), 
            col="red", lty=2)+
  theme_light()
```

```{r}
for(i in seq(12, 48, 12)) {
  for (j in seq(12, 48, 12)) {
    Tabla_1<- Obs_Data %>% mutate(diff_nivel=c(NA,diff(nivel))) 
Tabla_1<- left_join(Tabla_1, WRF_data[[23]]$D1[,c("Date", "prep_hourly")], by="Date")


# Parte1: Predecir aportacion a partir de diferencia de nivel... 
Tabla_1[,c("Vol","Temp", "porcentaje","prep_hourly")]<- NULL
Tabla_2<- Tabla_1[complete.cases(Tabla_1),]
Tabla_2$aport_SMA<- SMA(Tabla_2$aport, i)
Tabla_2$difnivel_SMA<- SMA(Tabla_2$diff_nivel, j)
Tabla_2<- Tabla_2[complete.cases(Tabla_2),]


train_data<- Tabla_2[Tabla_2$Date< ymd("2019/01/25"), ]
prediccion_data<- Tabla_2[Tabla_2$Date> ymd("2019/01/25"), ]



modelo<- train(aport_SMA ~ difnivel_SMA,
               data=train_data,
               method="svmLinear")


graph<- ggplot(data = prediccion_data)+
  geom_line(aes(y=prediccion_data$aport, 
                x=prediccion_data$Date), 
            alpha=0.5)+
  geom_line(aes(y=prediccion_data$aport_SMA, 
                x=prediccion_data$Date), 
            alpha=0.8)+
  ylab("Aportacion [m³/s]")+
  xlab(paste(range(prediccion_data$Date), collapse = "\n"))+
  geom_line(aes(y=predict(modelo, newdata= prediccion_data),
                x=Date), 
            col="red", lty=2)+
  theme_light()+ labs(subtitle = paste0("MA en la aportacion de ",
                                        i,
                                        "\nMA en la variacion nivel de ", 
                                        j,
                                        "\nCor= ", 
                                        round(cor(predict(modelo, 
                                                          newdata= prediccion_data),
                                                  prediccion_data$aport_SMA), digits = 3)))
print(graph)
  }

  
}
```




En función de los valores de SMA observados en las gráficas anteriores se eligirán los valores con los que se pretender seguir trabajando.Se puede apreciar que realizando una MA es más sencillo conseguir buenos resultados y más fácil predecir, pero hay que tener en cuenta que se aleja de la realidad (onda gris oscilante). A mi la que más me gusta es la de SMA aport 12 y SMA diff nivel de 36. 
